# Data Science como ferramenta para reten√ß√£o de clientes da Olist

## **Introdu√ß√£o**

Este projeto tem como objetivo selecionar entre todos os clientes que utilizam o servi√ßo da Olist, identificar aqueles que apresentam dificuldades na realiza√ß√£o de suas vendas e propor estrat√©gias espec√≠ficas de acordo com o perfil de cliente afim de evitar a sa√≠da futura dos clientes da Olist.
Para alcan√ßar esse objetivo, foram selecionados vari√°veis de import√¢ncia extra√≠das do banco de dados da Olist e utilizados em diversos algoritmos de machine learning resultando no modelo com o melhor desempenho para a identifica√ß√£o destes clientes.

Neste relat√≥rio, apresento uma vis√£o geral da metodologia empregada e dos resultados obtidos, a fim de demonstrar como conhecimentos de Data Science podem ser aplicados em um problema de neg√≥cio. Os detalhes t√©cnicos e explica√ß√µes minuciosas de cada processo encontram-se no meu reposit√≥rio do [GitHub](https://github.com/thifujikawa/clientes_olist)

## **O que √© a Olist** 
<img src="img/logo_olist.png" width="300" height="100">

A Olist √© uma plataforma de e-commerce que utiliza sua expertise intermediando o vendedor com grandes sites de com√©rcio eletr√¥nico, de maneira que um √∫nico produto cadastrado seja distribu√≠do para os principais sites simultaneamente facilitando o vendedor e aumentando as chances de vendas.

<a name="voltar"></a>

## **Metodologia:**
Para este projeto foi realizado a divis√£o em diversas etapas:

1. [**Problema de Neg√≥cio**](#problema_negocio) Um Problema real de neg√≥cio que empresas como a Olist constamente enfrentam.
2. [**Entendimento dos dados**](#data_understanding) Compreender como o banco de dados esta estruturado.
3. [**Extra√ß√£o Transforma√ß√£o e Carga (ETL-*Extraction Transform Load*)**](#etl) Extra√ß√£o dos dados do banco, gera√ß√£o de vari√°veis para an√°lise
4. [**An√°lise Explorat√≥ria de Dados (EDA-*Exploratory Data Analysis*) e Constru√ß√£o do modelo**](#preproc) An√°lise explorat√≥ria dos dados, Processamento dos dados e Constru√ß√£o do modelo de machine learning
5. [**Resultados**](#resultados)
6. [**Implementa√ß√£o do modelo**](#implementa√ß√£o) Utiliza√ß√£o do algoritmo treinado para gera√ß√£o de scores dos vendedores
7. [**Estrat√©gia de Neg√≥cio**](#negocio) Como pode ser aplicada os resultados a fim de resolver o problema de neg√≥cio

<a name="problema_negocio"></a>

### **1 - Problema de neg√≥cio** 
A Olist √© uma startup que possui seu modelo de neg√≥cio baseado em assinaturas mensais e comiss√£o por vendas, portanto, √© de extrema import√¢ncia para a Olist que seus vendedores consigam concretizar vendas para permanecerem no neg√≥cio. Outro fator a ser considerado √© que neste tipo de neg√≥cio, manter um assinante na plataforma com estrat√©gias de reten√ß√£o costumam ser menos custosos camparadas as campanhas de marketing para aquisi√ß√£o de novos clientes.

#### **1.1 - Solu√ß√£o para o problema**
Afim de minimizar o n√∫mero de clientes que ir√£o deixar a Olist, ser√° utilizado o banco de dados para criar um modelo preditivo e assim determinar quais ser√£o as chances deste cliente deixar de realizar vendas utilizando a plataforma, desta maneira, pode-se realizar determinadas campanhas, a√ß√µes ou consultorias direcionadas aos usu√°rios com o intuito de evitar que os usu√°rios abandonem a empresa.

[**Voltar**](#voltar)

<a name="data_understanding"></a>

### **2 Data Understanding (*Entendimento dos dados*)**   

<figure>
<center><img src="img/dbmap.png"> </center>
<figcaption> Figura1: Esquema do banco de dados da Olist </figcaption> 
</figure>

Com o problema identificado e o que se espera da resposta do algoritmo, o pr√≥ximo passo √© compreender o banco de dados. Para esta etapa, √© fundamental que a empresa possua uma boa estrutura no banco de dados, pois um bom modelo de machine learning depende dos dados deste banco para o treinamento do algoritmo.

A base de dados da Olist foi elaborada em star scheme (Esquema Estrela), modelo amplamente adotado em data warehouses.Pode-se observar na figura 1, onde no centro temos a tabela *orders_dataset* rodeadas de tabelas auxiliares. As tabelas auxiliaries cont√©m informa√ß√µes relacionadas a forma de pagamento, itens comprados, avalia√ß√£o da compra por parte de comprador, dados dos compradores entre outros

A tabela *olist_orders_dataset* possui todos os pedidos realizados durante o periodo de 15/09/2016 √† 3/09/2018 totalizando 99441 registros.

No in√≠cio havia idealizado uma solu√ß√£o do problema focado nos usu√°rios que sairam da plataforma, por√©m infelizmente como as tabelas focam apenas em dados referente a ordens de compra e n√£o aos usu√°rios que entraram e sairam da plataforma, tive que alterar abordagem do problema, por isto e outros motivos esta etapa √© uma das etapas fundamentais.

[**Voltar**](#voltar)
<a name="etl"></a>

### **3 - Extra√ß√£o Transforma√ß√£o e Carga (ETL-*Extraction Transform Load*)**  

Nesta fase re√∫ne-se dados de diferentes tabelas em apenas uma tabela, a sele√ß√£o.
Para selecionar quais destes dados ir√£o para tabela √© preciso um conhecimento pr√©vio do neg√≥cio, pois √© atrav√©s do uso destes indicadores que o algoritmo compreender√° o comportamento dos clientes que tendem a n√£o realizar vendas.
Al√©m das vari√°veis geradas citadas acima para que o algoritmo possa compreender as altera√ß√µes √© necess√°rio que ele saiba quais clientes realizaram ou n√£o vendas nos pr√≥ximos 3 meses, isto √© chamado de vari√°vel resposta, portanto, nesta tabela teremos as variaveis geradas junto a vari√°vel resposta.
Abaixo segue algumas estrat√©gias utilizadas para a confec√ß√£o da tabela.

### Gera√ß√£o das Safras   
Como a base de dados possui apenas dados relacionados a vendas realizadas durante 2 anos, criei parti√ß√µes destes dados, que nada mais s√£o que um agrupamento dos dados dos vendedores de um determinado periodo, neste caso, foi considerado um periodo de 6 meses de atividade deste vendedor e nos 3 meses seguintes se houve alguma venda.   
Exemplo:  
Os dados de vendas do usu√°rio durante os meses de Janeiro e Junho foram coletados processados e enviados para a tabela.J√° a vari√°vel resposta ir√° considerar se houve vendas nos pr√≥ximos 3 meses ap√≥s o mes de Julho, desta maneira o algoritmo pode avaliar de acordo comportamento do usu√°rio no periodo observado e se houve ou n√£o vendas.   
As safras selecionadas contemplam os seguintes dados:

|Safra       | Comportamento do usu√°rio nos meses   | Periodo observado se houve vendas     |
|----------- |----------------                      | ----------------                      |
|Abr/17      | Out/16 √† Abr/17                      | Mai/17 √† Jul/17                       |
|Mai/17      | Nov/16 √† Mai/17                      | Jun/17 √† Set/17                       |
|Jun/17      | Dez/16 √† Jun/17                      | Jul/17 √† Out/17                       |
| &mdash;    | &mdash;                              | &mdash;                               |
|Mai/18      | Nov/17 √† Mai/19                      | Jun/18 √† Set/18                       |

### Cria√ß√£o das Vari√°veis   
Definida a estrat√©gia de particionar os dados gerando safras o pr√≥ximo passo √© reunir todas as informa√ß√µes pertinentes a este problema em uma √∫nica tabela.
Nesta tabela, as linhas temos dados do usu√°rio e as colunas informa√ß√µes pertinentes a este usu√°rio. Esta e a etapa anterior sobre o entendimento dos dados s√£o de grande import√¢ncia para o sucesso do projeto, pois √© atrav√©s do refinamento correto de dados das informa√ß√µes referente ao usu√°rio que permitir√£o auxiliar e obter sucesso do treinamento do modelo.
Abaixo demonstro as vari√°veis geradas e utilizadas neste projeto.

|Vari√°vel                       |Descri√ß√£o                                                              |
|-----------                    |----------------                                                       |
|Safra                          |Indica a Safra do dado                                                 |
|Seller ID                      |Identifica√ß√£o do Usu√°rio                                               |
|flag venda                     |Indica se houve vendas nos 3 meses seguintes (Vari√°vel Resposta)       |
|estado                         |Estado do Usu√°rio                                                      |
|idade_dias                     |Qtde de dias que entrou na Plataforma                                  |
|qtde_vendas                    |Qtde de Vendas                                                         |
|variedade_prod                 |Variedade de Produtos Vendidos                                         |
|qtde_prod_vendidos             |Quantidade de Produto Vendidos                                         |
|media_prod_vendidos_order      |M√©dia da Quantidade de Produtos Vendidos por ordem                     |
|media_fotos                    |M√©dia de Fotos nos An√∫ncios                                            |
|media_letras_desc              |M√©dia de Letras Utilizadas nas Descri√ß√µes                              |
|avaliacao_safra                |Avalia√ß√£o das vendas na Safra                                          |
|avaliacao_acumulada            |Avalia√ß√£o das vendas desde que entrou na Olist                         |
|delta_avaliacao_idade_base     |Diferen√ßa entre avalia√ß√£o Acumulada e da Safra                         |
|ultima_venda                   |Qtde em dias da √∫ltima venda                                           |
|qtde_mes_ativos                |Qtde de meses que realizou vendas na safra                             |
|prop_atrasos                   |Propor√ß√£o de atrasos no recebimento que ocorreram nas vendas           |
|media_prazo_entrega            |M√©dia em dias do prazo de entrega                                      |
|ticket_medio                   |M√©dia do valor gasto por venda                                         |
|valor_medio_prod               |M√©dia do valor dos produtos vendidos                                   |
|total_mensal                   |Total Mensal de vendas                                                 |
|frete_medio                    |Valor m√©dio do Frete                                                   |
|prop_valor_frete               |Propor√ß√£o entre o valor do frete e do Produto                          |
|intervalo_pedidos_dias         |Quantidade de vendas realizadas durante uma safra (6 meses)            |

### Execu√ß√£o da Etapa
A Etapa de Extra√ß√£o, Transforma√ß√£o e Carregamento dos dados (***ETL***) foi elaborada da seguinte maneira:   
Sele√ß√£o das Vari√°veis : Um arquivo em formato SQL, efetua a sele√ß√£o e cria√ß√£o das vari√°veis acessando as diferentes tabelas e cruzando dados quando necess√°rio.
Cria√ß√£o da tabela com safras: Um arquivo utilizando linguagem Python realiza a cria√ß√£o da tabela. Ao usu√°rio inserir a data de in√≠cio da safra e a quantidade desejada de safras, preenche a tabela utilizando o arquivo de sele√ß√£o de vari√°veis. Deste maneira em um tabela temos as safras e todas as vari√°veis que foram escolhidas;

[**Voltar**](#voltar)
<a name="preproc"></a>

### **4 ‚Äì An√°lise Explorat√≥ria de Dados (EDA - Exploratory Data Analysis) e Constru√ß√£o do modelo** 

Ap√≥s a gera√ß√£o da tabela e o preenchimento com dados dos vendedores, chega a fase de an√°lise dos dados, esta an√°lise se iniciou avaliando o tamanho da tabela (Linhas X Colunas), em seguida quais tipos de vari√°veis a tabela possui (Nominais, Ordinais, Discretas e Continuas), nesta etapa ocorreram algumas corre√ß√µes j√° que dados num√©ricos haviam sido interpretados como caracteres.
Ap√≥s a corre√ß√£o dos dados se iniciou a An√°lise Explorat√≥ria dos dados √© de suma import√¢ncia e tem como objetivo de identificar previamente os dados discrepantes, a normalidade da distribui√ß√£o de frequ√™ncias e a varia√ß√£o dos dados. Muitas vezes os valores discrepantes demonstram problemas, erro de digita√ß√£o, fraudes, diferente moeda monet√°ria.
Atrav√©s da An√°lise Explorat√≥ria permitiu notar que:
* Presen√ßa de valores ausentes na tabela e necessitou estrat√©gias de substitui√ß√£o que ser√£o realizadas na fase de modelagem para evitar vi√©s.
* Ao verificar a distribui√ß√£o dos dados de maneira gr√°fica alguns vendedores demonstraram um comportamento estranho(Vendedores com poucas vendas com Valor da venda muito alto e baixa avali√ß√£o) ao investigar um pouco mais estes usu√°rios no banco de dados pode-se notar que s√£o poss√≠veis fraudadores, j√° que estes usu√°rios n√£o haviam recebido seus produtos ou receberam modelo n√£o condizentes ao an√∫ncio. Como estes usu√°rios n√£o s√£o interessantes para este projeto os mesmos foram removidos da tabela.
* Atrav√©s da visualiza√ß√£o de correla√ß√£o entre vari√°veis foram excluidas 2 vari√°veis pois estavam altamente corelacionadas as outras, desta maneira evitamos que o algoritmo de considere vari√°veis que estariam explicando a mesma coisa.
Ap√≥s a an√°lise explorat√≥ria, a √∫ltima safra foi separada e

Ao t√©rmino da An√°lise Explorat√≥ria pode-se compreender e tratar os dados. Tendo os dados "tratados" a etapa de modelagem do algoritmo se iniciou.

### Modelagem
Para iniciar e avaliar o modelo foi retirada a √∫ltima safra do *dataset*(tabela que foi processada anteriormente), esta ser√° utilizada pr√≥ximo do fim do projeto com o objetivo de avaliar como o algoritmo ir√° se comportar com dados novos.
Para verificar se um algoritmo performa bem n√£o se pode utilizar os dados que foram utilizados para treino. Pois s√£o dados que j√° foram vistos pelo algoritmo (√© como se voc√™ j√° tivesse visto o gabarito de um teste). Nesta etapa foi utilizada a Valida√ß√£o Cruzada e KFolds que separa o dataset em K partes onde 1 desta parte √© selecionada para teste e as restantes para treino, tendo um modelo treinado com estas partes ele utiliza os dados de teste e baseado na resposta que o modelo previu temos um resultado, este √© confrontado com o valor que j√° se sabe e temos a quantidade de acertos e erros. A Valida√ß√£o Cruzada com KFolds √© um processo iterativo onde se temos 10 folds esta valida√ß√£o ser√° feita 10 vezes, cada uma utilizando 1 fold diferente para teste.
Como existem diversos algoritmos de machine learning cada um com suas qualidades e defeitos, foi selecionados alguns afim de criar modelos de previs√£o, atrav√©s desta previs√£o pode-se ter um panorama de como os algoritmos errou/acertou.

<figure>
<center><img src="img/baseline.png" height="110%"> </center>
<figcaption> Figura2: Resultados obtidos na fase de sele√ß√£o do algoritmo </figcaption> 
</figure>

A m√©trica utilizada para avaliar os resultado foi a F1 Score. Na Figura 2 pode-se observar que o modelo LGBMClassifier(Light Gradient Boosting Machine) forneceu os melhores resultados. Baseado nestes resultados e tendo escolhido o modelo a ser utilizado e iniciou-se a etapa de otimiza√ß√£o do algoritmo.
Para maximizar a quantidade de acertos o modelo possui parametros que podem ser alterados, esta etapa possui um alto custo computacional pois dado alguns parametros ele ir√° realizar todas as combina√ß√µes poss√≠veis, algumas estrat√©gias foram adotadas nesta etapa afim de diminuir o n√∫mero de combina√ß√µes e achar um resultado mais r√°pido.
No in√≠cio desta etapa foi citado a respeito da ultima safra retirada do dataset, nesta etapa ela foi utilizada, desta maneira esses dados s√£o novos para o modelo j√° que ele foi retirado da fase inicial do processo.


[**Voltar**](#voltar)
<a name="resultados"></a>

### **5 ‚Äì Resultados** 

Atrav√©s do dataset de Out of Time que foi retirado no in√≠cio do processo pode-se ter verificar como o modelo esta prevendo novos dados que n√£o foram utilizados na fase de modelagem do sistema.

<figure>
<center><img src="img/f1score_opt.png" width="600" height="700"> </center>
<figcaption> Figura3: Resultados da fase de otimiza√ß√£o F1 Score e Precision Recall </figcaption> 
</figure>

A Figura 3 demonstra os resultados do modelo em 2 dataset o Dataset de Teste foi utilizado na fase de otimiza√ß√£o e o Dataset Out of Time n√£o havia sido utilizado em nenhum momento durante a fase de treinamento do algoritmo, portanto, s√£o dados totalmente novos para o modelo.
Ao avaliar os resultados obtidos atrav√©s do modelo utilizando o dataset Out of Time temos:
* 68% de precis√£o, isto √©, o modelo acertou em 68% dos usu√°rios que n√£o fizeram vendas nos pr√≥ximos 3 meses;
* 78% de revoca√ß√£o/recall, de todos os usu√°rios que n√£o venderam o modelo pode capturar 78% das pessoas deste grupo.

[**Voltar**](#voltar)
<a name="implementa√ß√£o"></a>

### **6 ‚Äì Implementa√ß√£o do modelo** 

Para implementar este modelo, foi criado um arquivo em formato Pickle contendo o modelo e parametros necess√°rios para o modelo funcionar corretamente.
Geralmente problemas desse tipo o modelo responde apenas de 0 ou 1 (Ir√° ou nao realizar vendas), mas existe a possibilidade do modelo enviar a resposta em probabilidade. Atrav√©s da probabilidade podemos classificar em grupos estes usu√°rios de acordo com a chance de efetuar vendas.

<figure>
<center><img src="img/scores.png" width="350" height="100"> </center>
<figcaption> Figura4: Scores dos usu√°rios </figcaption> 
</figure>

Na Figura 4 temos o modelo prevendo as chances de cada usu√°rio n√£o realizar as vendas, estes resultados estarei chamando de scores dos vendedores.
Com o ID do Vendedor junto ao seu respectivo score √© enviada para uma nova tabela no banco de dados. Esta Tabela pode ser fornecida para o departamento respons√°vel pelas a√ß√µes de reten√ß√£o dos usu√°rios. 

[**Voltar**](#voltar)
<a name="negocio"></a>

### **7 ‚Äì Poss√≠veis estrat√©gias de neg√≥cio** 
 
Com a tabela com usu√°rios e respectivos score podemos estudar como atuar para impulsionar as vendas utilizando diferentes campanhas para os vendedores. Com estes resultados foi poss√≠vel separar os vendedores em 4 grupos de acordo com o score:


| Intervalo entre os scores &nbsp; &nbsp;| A√ß√µes |
|:----------: | :------------- | 
| **1 e 0,81** | Possuem uma grande chance de n√£o realizarem vendas e podem ser ofertadas solu√ß√µes que requeiram um investimento maior como: uma consultoria personalizada, desconto na comiss√£o das vendas, meses gr√°tis na plataforma.|
|**0,8 e 0,61** | Para este grupo de vendedores podem ser aplicados outras campanhas de reten√ß√£o que n√£o exijam tanto investimento quanto ao grupo anterior: envio de e-mails com melhores pr√°ticas para vendas, aumentar a relev√¢ncia e o alcance, aumentar a variedades de produtos na plataforma afim de melhorar as vendas.|
|**0,6 e 0,3**  | Estes vendedores ainda podem representar um potencial risco de n√£o realizar vendas portanto campanhas de e-mails contendo as tend√™ncias de vendas atuais e outras an√°lises podem aumentar ainda mais as chances de vendas.|
|**0,3 e 0** | Representam clientes que potencialmente v√£o realizar vendas e que n√£o ser√£o foco para este case.|

## Considera√ß√µes finais
Este projeto pode abranger desde in√≠cio de um projeto da Data Science partindo de um problema de neg√≥cio, utiliza√ß√£o do banco de dados da empresa, extra√ß√£o e an√°lise dos dados, sele√ß√£o e otimiza√ß√£o do algoritmo de machine learning e por fim um programa que utiliza o algoritmo de machine learning para realizar o score dos vendedores. A partir destes scores pode-se realizar agrupamentos para campanhas distintas de reten√ß√£o.   
Sou formado em engenharia e em todos projetos que participei busquei acompanhar todo os passos do projeto, atrav√©s desta participa√ß√£o pude adquirir conhecimentos de √°reas totalmente adversas a que trabalhava e que de forma direta ou indireta contribuiram em diversos projetos e me agregou diversos conhecimentos.

[**Voltar**](#voltar)

## üôç Autor <a name="autor"></a>
Feito por Thiago Ide.

[![Linkedin Badge](https://img.shields.io/badge/-Thiago-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/thide)](https://www.linkedin.com/in/thide/)
[![Gmail Badge](https://img.shields.io/badge/-thiago.fudji@gmail.com-c14438?style=flat-square&logo=Gmail&logoColor=white&link=mailto:thiago.fudji@gmail.com)](mailto:thiago.fudji@gmail.com)