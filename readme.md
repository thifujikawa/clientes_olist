# Detec√ß√£o de clientes que n√£o realizar√£o vendas na Olist

## Descri√ß√£o do Projeto

Utilizando Data Science e o Banco de dados da Olist, elaborei um projeto onde pode-se realizar uma Extra√ß√£o do banco de dados trata-los para em seguida realizar alguns algoritmos de machine Learning afim de encontrar clientes que tendem a n√£o realizar vendas na plataforma da Olist. Assim determinadas a√ß√µes podem ser realizadas afim de auxiliar este vendedor.

## Tabela de conte√∫dos

* [Sobre](#sobre)
* [Tabela de Conte√∫do](#tabela_de_conteudo)
* [Instala√ß√£o](#instalacao)
* [Como Usar](#como_usar)
    * [Pr√© Requisitos](#pre-requisitos)
    * [Local Files](#local-files)
* [Descri√ß√£o do Projeto](#projeto)
* [Tests](#testes)
* [Tecnologias](#tecnologias)
* [Autor](#autor)


## Status do Projeto

<h4 align="center">

    üöß Em constru√ß√£o... üöß
    Desenvolvendo a documenta√ß√£o

## Features
- [x] Envio do Projeto para o Github
- [ ] Passar o Banco de dados para Download
- [ ] Melhorar a documenta√ß√£o no GitHub e Notebook

<a name="como_usar"></a>
## Como Usar 

<a name="pre-requisitos"></a>
## Pr√© Requisitos 
Antes de come√ßar, voc√™ vai precisar ter instalado em sua m√°quina as seguintes ferramentas:
- [Git]
- [Python](https://www.python.org)
- [SQL]

Para a execu√ß√£o do projeto ser√° necess√°rio a extra√ß√£o dos dados diretamente de um banco, portanto √© necess√°rio o download de alguns arquivos.
<a name="local-files"></a>
### Local Files 
* Realizar o Download do reposit√≥rio e do banco de dados conforme as instru√ß√µes abaixo:
    1. Clonar o [reposit√≥rio](https://github.com/thifujikawa/clientes_olist.git)
    2. Efetuar o Download do Banco de dados da Olist 

***OBSERVA√á√ÉO*** O banco de dados deve estar salvo no diret√≥rio Data

* Instalar as bibliotecas:
    1. No Reposit√≥rio o arquivo requirements.txt possui todas as bibliotecas necess√°rias para o projeto.

<a name="projeto"></a>
## Descri√ß√£o do Projeto:

O Projeto como um todo possui 5 etapas, sendo que 3 contemplam notebooks e scripts.  
[Neste link](https://thifujikawa.github.io/clientes_olist/) escrevi um pouco mais sobre os detalhes desse projeto.  
Abaixo estarei descrevendo um pouco mais sobre as etapas por√©m darei enfase para as etapas com c√≥digo.  
- **Etapa 1/5** - Problema de neg√≥cio: Diminui√ß√£o do churn, sendo que o algoritmo ser√° respons√°vel em detectar vendedores que n√£o ir√£o realizar vendas nos pr√≥ximos 3 meses. Tendo definido estes vendedores a√ß√µes possam ser tomadas;  

- **Etapa 2/5** - Extraction Transform and Load (***ETL***): Utilizando o banco de dados da Olist foi realizada uma query (***query_abt.sql***) que ao ser executada pelo script (***gera√ß√£o_abt.py***) cria uma Analytical Base Table (ABT) com os dados coletados pela query, inclusive a vari√°vel resposta que nesse caso verifica se a partir da data do fim da safra houveram vendas nos pr√≥ximos 3 meses.  
Instru√ß√µes para execu√ß√£o para a gera√ß√£o da ABT:
    * No diret√≥rio Query executar via terminal de comando o arquivo **geracao_abt.py** e inserir:  
        - -s : A data inicial de coleta das safras respeitando o formato(YYYY-MM-DD)  
        - -i : Quantidade de safras que ser√£o geradas   
        O programa ir√° criar uma tabela de nome **tb_abt_no_sells** contendo todos os dados referente a ABT e suas respectivas safras.  
>
- **Etapa 3/5** - Processamento, Explora√ß√£o dos dados e Constru√ß√£o do modelo: Com a ABT foi criado um notebook (***modelling.ipynb***) onde foi feita a An√°lise Explorat√≥ria de Dados que auxiliou na detec√ß√£o de outliers, disposi√ß√£o dos dados e na defini√ß√£o de estrat√©gias para preencher dados nulos contidos no dataset, em seguida foi escolhido o algoritmo e otimizado o algoritmo de machine learning. O algortimo e dados adicionais referente as vari√°veis foram salvos em um arquivo pickle (***modelo_otimizado.pkl***).  

- **Etapa 4/5** - Operacionaliza√ß√£o Com o arquivo Pickle contendo o algoritmo e todos os dados para a execu√ß√£o √© poss√≠vel utilizar novos dados afim de localizarmos esses vendores. O script (***get_last_model.py***) atrav√©s da query  (***query_book_variaveis.sql***), cria uma tabela (***tb_book_sellers***), esta tabela √© semelhante a ABT, por√©m neste caso n√£o temos a vari√°vel resposta pois quem ir√° fornecer essa resposta ser√° o resultado desse algoritmo. Um pouco diferente do normal, ao inv√©s do algoritmo a classifica√ß√£o responder atrav√©s de (0 ou 1) estou utilizando a probabilidade porntanto, o valor ser√° entre 0 e 1 sendo que quanto mais pr√≥ximo do valor 1 maiores s√£o as chances do vendedor n√£o realizar vendas. Uma tabela ser√° criada (***tb_no_sells_score***) contendo o ID do Vendedor e seu respectivo score.  
Instru√ß√µes para execu√ß√£o:  
Gera√ß√£o dos scores:  
    * No diret√≥rio Modelling executar via terminal de comando o arquivo **get_last_model.py** e inserir:
        - -s : A data inicial da safra desejada neste caso para prevermos a possibilidade de vendas nos pr√≥ximos 3 meses inserir a data da safra a partir do √∫ltimo registro -6 meses.  
        - O programa ir√° gerar os scores e enviar para a tabela **tb_no_sells_score**  
>
- **Etapa 5/5**  - Poss√≠veis estrat√©gias de neg√≥cio: No [GithubPages](https://thifujikawa.github.io/clientes_olist/) descrevi melhor uma poss√≠vel estrat√©gia de reten√ß√£o de clientes, por√©m de modo resumido quanto maiores as chances do vendedor n√£o realizar vendas, mais poderia ser investido nestes usu√°rios afim de ajuda-los.  

## Notebook contendo o desenvolvimento do algoritmo de Machine Learning:  
Para quem se interessar em olhar no projeto de Data Science com as respectivas m√©tricas e m√©todos utilizados o mesmo se  encontra neste reposit√≥rio na pasta Modelling o arquivo **modelling.ipynb** voc√™ poder√° ver com mais detalhes o que foi aplicado.   
De maneira resumida o algoritmo de machine learning escolhido para esta tarefa foi o Light Gradient Boosting e em um dataset Out of Time obteve um AUC_SCORE de 0.89 e levando em considera√ß√£o grupo que n√£o realizar√° vendas, as m√©tricas **Precision/Recall** obtidas foram de respetivamente **0.73 e 0.76**.  
O Arquivo **modelo_otimizado.pkl** contem os Pipeline completo incluindo o algoritmo aplicando as devidas otimiza√ßoes. 

<a name="tecnologias"></a>
## üõ† Tecnologias 

- [Python](https://www.python.org)
- [SQL]()

<a name="autor"></a>
## üôç Autor
Feito por Thiago Ide.

[![Linkedin Badge](https://img.shields.io/badge/-Thiago-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/thide)](https://www.linkedin.com/in/thide/)
[![Gmail Badge](https://img.shields.io/badge/-thiago.fudji@gmail.com-c14438?style=flat-square&logo=Gmail&logoColor=white&link=mailto:thiago.fudji@gmail.com)](mailto:thiago.fudji@gmail.com)


## üìö Licen√ßa

MIT License

Copyright (c) <2020> <Seu Nome>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
